import ftplib
import pandas as pd
import mysql.connector
from io import StringIO, BytesIO  # Include BytesIO for binary data handling
import os
import functions_framework
import logging
from google.cloud.sql.connector import Connector
import pymysql

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Environment Variables (set in Google Cloud Function)
FTP_HOST = "ftpjobs.hittraxbaseball.com"
FTP_USER = "ReplayBaseball"
FTP_PASS = "(*FH#$Inife34s3"
MYSQL_HOST = "35.199.22.103"
MYSQL_USER = "root"
MYSQL_PASS = "NALjjl112497!"
MYSQL_DB = "PlayerDev"

# File prefix-to-table mapping
FILE_TABLE_MAPPING = {
    "PlaysExport": "HitTraxPlays",
    "SessionExport": "HitTraxSessions"
}

def connect_to_ftp():
    try:
        logger.info("Connecting to FTP server...")
        ftp = ftplib.FTP_TLS(FTP_HOST)
        ftp.login(FTP_USER, FTP_PASS)
        ftp.prot_p()  # Enable secure data connection
        ftp.set_pasv(True)  # Enable passive mode
        logger.info("Connected to FTP server.")
        return ftp
    except Exception as e:
        logger.error(f"Failed to connect to FTP: {e}")
        raise

def connect_to_mysql():
    """Connects to a Google Cloud SQL MySQL database using the Python Connector."""
    try:
        logger.info("Connecting to MySQL database via Cloud SQL Connector...")
        
        # Create a Connector instance
        connector = Connector()
        
        # Define the connection name for your Cloud SQL instance
        connection_name = "norse-coral-441421-r9:us-east4:replay-baseball-player-dev"
        
        # Use the connector to establish the connection
        conn = connector.connect(
            connection_name,
            "pymysql",
            user="root",  # Replace with your MySQL username
            password="NALjjl112497!",  # Replace with your MySQL password
            db="PlayerDev",  # Replace with your database name
        )
        
        logger.info("Successfully connected to MySQL database.")
        return conn
    except Exception as e:
        logger.error(f"Failed to connect to MySQL: {e}")
        raise

def process_csv_file(file_name, table_name, ftp):
    """Processes a CSV file from FTP and inserts its data into MySQL."""
    try:
        logger.info(f"Processing file: {file_name} for table {table_name}...")

        # Download the file into binary memory
        file_data = BytesIO()
        ftp.retrbinary(f"RETR {file_name}", file_data.write)
        file_data.seek(0)  # Reset the buffer pointer to the start

        # Decode the binary content into a string
        file_content = file_data.read().decode('utf-8')

        # Load the CSV content into a pandas DataFrame
        df = pd.read_csv(StringIO(file_content))

        # Clean up and prepare the DataFrame
        df.columns = [col.strip() for col in df.columns]  # Remove extra spaces from column names

        # Replace NaN values with None for MySQL compatibility
        df = df.where(pd.notnull(df), None)

        # Insert data into MySQL
        conn = connect_to_mysql()
        cursor = conn.cursor()

        cols = ",".join(df.columns)
        placeholders = ",".join(["%s"] * len(df.columns))
        insert_query = f"INSERT INTO {table_name} ({cols}) VALUES ({placeholders})"

        for _, row in df.iterrows():
            row_data = [None if pd.isna(value) else value for value in row]  # Explicitly handle NaN as None
            cursor.execute(insert_query, tuple(row_data))

        # Commit the transaction and close the connection
        conn.commit()
        cursor.close()
        conn.close()

        logger.info(f"Successfully processed file: {file_name} into table: {table_name}")

    except mysql.connector.Error as e:
        logger.error(f"MySQL error occurred while processing {file_name}: {e}")
    except Exception as e:
        logger.error(f"Error processing file {file_name}: {e}")



@functions_framework.http
def ftp_to_mysql(request):
    try:
        logger.info("Starting FTP-to-MySQL ingestion process.")
        ftp = connect_to_ftp()
        ftp.cwd("/")  # Adjust this to your FTP directory
        logger.info("Fetching file list from FTP server.")

        # List all files on the FTP server
        files = ftp.nlst()
        logger.info(f"Files found on FTP server: {files}")

        for file_name in files:
            # Match file prefix to the corresponding table
            matched_table = None
            for prefix, table_name in FILE_TABLE_MAPPING.items():
                if file_name.startswith(prefix):
                    matched_table = table_name
                    break  # Exit loop once a match is found

            if matched_table:
                try:
                    logger.info(f"Processing matched file: {file_name} for table: {matched_table}")
                    process_csv_file(file_name, matched_table, ftp)
                    delete_file_from_ftp(file_name, ftp)
                except Exception as e:
                    logger.error(f"Error processing file {file_name}: {e}")

        ftp.quit()
        logger.info("FTP connection closed.")
        logger.info("Data ingestion completed successfully.")
        return "Data ingestion completed successfully.", 200
    except Exception as e:
        logger.error(f"Critical error in ingestion process: {e}")
        return f"Error: {e}", 500

def delete_file_from_ftp(file_name, ftp):
    try:
        logger.info(f"Deleting file: {file_name}")
        ftp.delete(file_name)
        logger.info(f"File {file_name} deleted from FTP server.")
    except Exception as e:
        logger.error(f"Error deleting file {file_name}: {e}")
        raise
